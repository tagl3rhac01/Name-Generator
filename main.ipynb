{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = open(\"names.txt\" , \"r\" , encoding=\"utf8\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ['.'] + sorted(list(set(\"\".join(names))))\n",
    "stoi = {ch : i for i , ch in enumerate(chars)}\n",
    "itos = {i : ch for i , ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minLen = min(len(i) for i in names)\n",
    "maxLen = max(len(i) for i in names)\n",
    "minLen , maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 8\n",
    "N_EMBED = 10\n",
    "HIDDEN = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words):\n",
    "    x , y = [] , []\n",
    "    for w in words:\n",
    "        context = [0] * BLOCK_SIZE\n",
    "        for i in w + '.':\n",
    "            ix = stoi[i]\n",
    "            x.append(context)\n",
    "            y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "    return torch.tensor(x) , torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = int(0.8 * len(names))\n",
    "n2 = int(0.9 * len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , y_train = build_dataset(names[:n1])\n",
    "x_val , y_val = build_dataset(names[n1 : n2])\n",
    "x_test , y_test = build_dataset(names[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    nn.Embedding(len(chars) , N_EMBED),\n",
    "    nn.Flatten() , \n",
    "    nn.Linear(BLOCK_SIZE * N_EMBED , HIDDEN),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(HIDDEN , len(chars))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for layer in layers:\n",
    "    params.extend(layer.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in params:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 50000 -> 1.7274\n",
      "10000 / 50000 -> 1.6724\n",
      "20000 / 50000 -> 1.7146\n",
      "30000 / 50000 -> 1.7861\n",
      "40000 / 50000 -> 1.8459\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    ix = torch.randint(0 , x_train.shape[0] , (BATCH_SIZE , ))\n",
    "    xtr = x_train[ix]\n",
    "    ytr = y_train[ix]\n",
    "    x = xtr\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    loss = F.cross_entropy(x , ytr)\n",
    "    for p in params:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    lr = 0.01 if i < 25000 else 0.001\n",
    "    for p in params:\n",
    "        p.data += -lr * p.grad\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"{i} / {EPOCHS} -> {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss -> 2.7601\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = x_val\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    loss = F.cross_entropy(x , y_val)\n",
    "    print(f\"Val Loss -> {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss -> 2.7879\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = x_test\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    loss = F.cross_entropy(x , y_test)\n",
    "    print(f\"Val Loss -> {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namarev\n",
      "nampa\n",
      "namshov\n",
      "namov\n",
      "namb\n",
      "namles\n",
      "nambett\n",
      "namobawa\n",
      "namokov\n",
      "nampa\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inp = input(\"Enter the first character : \")\n",
    "    inp2 = input(\"Enter the second character : \")\n",
    "    inp3 = input(\"Enter the third character : \")\n",
    "    for i in range(10):\n",
    "        out = [stoi[inp] , stoi[inp2] , stoi[inp3]]\n",
    "        context = [0] * 5 + [stoi[inp] , stoi[inp2] , stoi[inp3]]\n",
    "        length = 0\n",
    "        while (length < 100):\n",
    "            length += 1\n",
    "            x = torch.tensor([context])\n",
    "            for layer in layers:\n",
    "                x = layer(x)\n",
    "            probs = F.softmax(x , dim = 1)\n",
    "            ix = torch.multinomial(probs , 1).item()\n",
    "            context = context[1:] + [ix]\n",
    "            if (ix == 0):\n",
    "                break\n",
    "            out.append(ix)\n",
    "        print(\"\".join(itos[i] for i in out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
